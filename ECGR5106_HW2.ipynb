{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anpham1331372/ECGR5106/blob/main/ECGR5106_HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SS_XOebEmaTe"
      },
      "outputs": [],
      "source": [
        "#alexnet cifar10 without dropout\n",
        "import datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "num_classes = 10\n",
        "\n",
        "# Normalize data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert labels to categorical\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Define a simplified VGG model\n",
        "class SimpleVGG(Sequential):\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        # First Conv Block\n",
        "        self.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu', input_shape=input_shape))\n",
        "        self.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "        self.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "\n",
        "        # Second Conv Block\n",
        "        self.add(Conv2D(128, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "        self.add(Conv2D(128, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "        self.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "\n",
        "        # Third Conv Block\n",
        "        self.add(Conv2D(256, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "        self.add(Conv2D(256, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "        self.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "\n",
        "        # Fully Connected Layers\n",
        "        self.add(Flatten())\n",
        "        self.add(Dense(512, activation='relu'))\n",
        "        self.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "        self.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Initialize model\n",
        "model = SimpleVGG((32, 32, 3), num_classes)\n",
        "\n",
        "# Training parameters\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True)\n",
        "train_generator = train_datagen.flow(x_train, y_train, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Logging for TensorBoard\n",
        "tensorboard_callback = TensorBoard(log_dir=\"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[tensorboard_callback],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Display final training results\n",
        "final_train_loss = history.history['loss'][-1]\n",
        "final_train_acc = history.history['accuracy'][-1]\n",
        "final_val_loss = history.history['val_loss'][-1]\n",
        "final_val_acc = history.history['val_accuracy'][-1]\n",
        "\n",
        "print(f\"\\nFinal Training Loss: {final_train_loss:.4f}\")\n",
        "print(f\"Final Training Accuracy: {final_train_acc:.4f}\")\n",
        "print(f\"Final Validation Loss: {final_val_loss:.4f}\")\n",
        "print(f\"Final Validation Accuracy: {final_val_acc:.4f}\")\n",
        "\n",
        "# Display training results graph\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plot Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss', color='blue')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss Over Epochs\")\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy', color='blue')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy Over Epochs\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEeE2M0h0Dqd"
      },
      "outputs": [],
      "source": [
        "#Modified ALexNet with CIFAR-10 WITH Dropout\n",
        "import datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "num_classes = 10\n",
        "\n",
        "# Normalize data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert labels to categorical\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Define a simplified AlexNet model with Dropout\n",
        "class SimpleAlexNet(Sequential):\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.add(Conv2D(64, kernel_size=(3,3), strides=1, padding='same', activation='relu', input_shape=input_shape))\n",
        "        self.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "        self.add(Dropout(0.25))\n",
        "\n",
        "        self.add(Conv2D(128, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "        self.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "        self.add(Dropout(0.25))\n",
        "\n",
        "        self.add(Conv2D(256, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "        self.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "        self.add(Dropout(0.25))\n",
        "\n",
        "        self.add(Flatten())\n",
        "        self.add(Dense(512, activation='relu'))\n",
        "        self.add(Dropout(0.5))\n",
        "        self.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "        self.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Initialize model\n",
        "model = SimpleAlexNet((32, 32, 3), num_classes)\n",
        "\n",
        "# Training parameters\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True)\n",
        "train_generator = train_datagen.flow(x_train, y_train, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Logging for TensorBoard\n",
        "tensorboard_callback = TensorBoard(log_dir=\"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[tensorboard_callback],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Display final training results\n",
        "final_train_loss = history.history['loss'][-1]\n",
        "final_train_acc = history.history['accuracy'][-1]\n",
        "final_val_loss = history.history['val_loss'][-1]\n",
        "final_val_acc = history.history['val_accuracy'][-1]\n",
        "\n",
        "print(f\"\\nFinal Training Loss: {final_train_loss:.4f}\")\n",
        "print(f\"Final Training Accuracy: {final_train_acc:.4f}\")\n",
        "print(f\"Final Validation Loss: {final_val_loss:.4f}\")\n",
        "print(f\"Final Validation Accuracy: {final_val_acc:.4f}\")\n",
        "\n",
        "# Display training results graph\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plot Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss', color='blue')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss Over Epochs\")\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy', color='blue')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy Over Epochs\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "illkld-V3eRz",
        "outputId": "b5b8b77b-a2d9-450e-a1d8-fa2c543f3df9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "\u001b[1m169001437/169001437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 0us/step\n",
            "Epoch 1/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 53ms/step - accuracy: 0.0099 - loss: 4.6066 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 2/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.0099 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 3/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.0102 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 4/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.0089 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 5/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.0094 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 6/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 45ms/step - accuracy: 0.0084 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 7/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.0095 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 8/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 44ms/step - accuracy: 0.0102 - loss: 4.6054 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 9/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 45ms/step - accuracy: 0.0090 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 10/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.0098 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 11/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.0098 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 12/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 45ms/step - accuracy: 0.0092 - loss: 4.6054 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 13/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 45ms/step - accuracy: 0.0094 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 14/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.0098 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 15/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.0097 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 16/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.0095 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 17/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.0106 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 18/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 45ms/step - accuracy: 0.0095 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 19/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.0095 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 20/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.0093 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 21/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.0098 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 22/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.0095 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 23/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 45ms/step - accuracy: 0.0092 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 24/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.0093 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 25/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.0091 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 26/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.0092 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 27/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.0096 - loss: 4.6054 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 28/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.0086 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 29/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.0096 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 30/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.0099 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 31/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.0099 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 32/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.0100 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 33/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 46ms/step - accuracy: 0.0090 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 34/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.0085 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 35/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.0095 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 36/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.0099 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 37/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.0099 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 38/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 45ms/step - accuracy: 0.0090 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 39/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.0096 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 40/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.0099 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 41/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.0094 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 42/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 45ms/step - accuracy: 0.0090 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 43/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.0098 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 44/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 45ms/step - accuracy: 0.0097 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 45/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.0100 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 46/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.0103 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 47/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.0087 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 48/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.0086 - loss: 4.6054 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 49/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.0097 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 50/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 44ms/step - accuracy: 0.0084 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 51/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 45ms/step - accuracy: 0.0100 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 52/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.0101 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 53/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 46ms/step - accuracy: 0.0108 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 54/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 45ms/step - accuracy: 0.0101 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 55/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 46ms/step - accuracy: 0.0091 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 56/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 45ms/step - accuracy: 0.0083 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 57/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 45ms/step - accuracy: 0.0093 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 58/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 45ms/step - accuracy: 0.0104 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 59/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 45ms/step - accuracy: 0.0092 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 60/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 45ms/step - accuracy: 0.0092 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 61/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 47ms/step - accuracy: 0.0103 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 62/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.0093 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 63/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 45ms/step - accuracy: 0.0089 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 64/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.0098 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 65/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.0092 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 66/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.0088 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 67/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 46ms/step - accuracy: 0.0106 - loss: 4.6054 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 68/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.0093 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 69/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.0100 - loss: 4.6054 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 70/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.0096 - loss: 4.6054 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 71/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 45ms/step - accuracy: 0.0097 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 72/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 45ms/step - accuracy: 0.0091 - loss: 4.6054 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 73/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 44ms/step - accuracy: 0.0094 - loss: 4.6054 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 74/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 45ms/step - accuracy: 0.0099 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 75/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 45ms/step - accuracy: 0.0093 - loss: 4.6054 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 76/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 46ms/step - accuracy: 0.0084 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 77/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 48ms/step - accuracy: 0.0083 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 78/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 48ms/step - accuracy: 0.0104 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 79/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.0098 - loss: 4.6054 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 80/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.0090 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 81/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 46ms/step - accuracy: 0.0097 - loss: 4.6054 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 82/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.0099 - loss: 4.6054 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 83/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 45ms/step - accuracy: 0.0097 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 84/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 46ms/step - accuracy: 0.0093 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 85/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.0089 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 86/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.0091 - loss: 4.6054 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 87/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 45ms/step - accuracy: 0.0096 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 88/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 46ms/step - accuracy: 0.0087 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 89/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.0091 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 90/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.0094 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 91/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 45ms/step - accuracy: 0.0093 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 92/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.0104 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 93/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 47ms/step - accuracy: 0.0096 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 94/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 45ms/step - accuracy: 0.0093 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 95/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.0092 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 96/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.0092 - loss: 4.6054 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 97/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.0089 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 98/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 45ms/step - accuracy: 0.0092 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 99/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 43ms/step - accuracy: 0.0097 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "Epoch 100/100\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.0093 - loss: 4.6055 - val_accuracy: 0.0100 - val_loss: 4.6052\n",
            "\n",
            "Final Training Loss: 4.6057\n",
            "Final Training Accuracy: 0.0086\n",
            "Final Validation Loss: 4.6052\n",
            "Final Validation Accuracy: 0.0100\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"simple_alex_net_3\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"simple_alex_net_3\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">166,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">663,936</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,327,488</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">884,992</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,195,328</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">102,500</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │           \u001b[38;5;34m2,688\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m192\u001b[0m)         │         \u001b[38;5;34m166,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_10 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m192\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m384\u001b[0m)           │         \u001b[38;5;34m663,936\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m384\u001b[0m)           │       \u001b[38;5;34m1,327,488\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m884,992\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_11 (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │       \u001b[38;5;34m4,195,328\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │       \u001b[38;5;34m1,049,600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │         \u001b[38;5;34m102,500\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,177,838</span> (96.05 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,177,838\u001b[0m (96.05 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,392,612</span> (32.02 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,392,612\u001b[0m (32.02 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,785,226</span> (64.03 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m16,785,226\u001b[0m (64.03 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#MOdified AlexNet with CIFAR 100 without Dropout\n",
        "import datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "# Load CIFAR-100 dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
        "num_classes = 100\n",
        "\n",
        "# Normalize data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert labels to categorical\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Define a simplified AlexNet model for CIFAR-100\n",
        "class SimpleAlexNet(Sequential):\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.add(Conv2D(96, kernel_size=(3,3), strides=1, padding='same', activation='relu', input_shape=input_shape))\n",
        "        self.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "\n",
        "        self.add(Conv2D(192, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "        self.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "\n",
        "        self.add(Conv2D(384, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "        self.add(Conv2D(384, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "        self.add(Conv2D(256, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "        self.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "\n",
        "        self.add(Flatten())\n",
        "        self.add(Dense(1024, activation='relu'))\n",
        "        self.add(Dense(1024, activation='relu'))\n",
        "        self.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "        self.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Initialize model\n",
        "model = SimpleAlexNet((32, 32, 3), num_classes)\n",
        "\n",
        "# Training parameters\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True)\n",
        "train_generator = train_datagen.flow(x_train, y_train, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Logging for TensorBoard\n",
        "tensorboard_callback = TensorBoard(log_dir=\"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[tensorboard_callback],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Display final training results\n",
        "final_train_loss = history.history['loss'][-1]\n",
        "final_train_acc = history.history['accuracy'][-1]\n",
        "final_val_loss = history.history['val_loss'][-1]\n",
        "final_val_acc = history.history['val_accuracy'][-1]\n",
        "\n",
        "print(f\"\\nFinal Training Loss: {final_train_loss:.4f}\")\n",
        "print(f\"Final Training Accuracy: {final_train_acc:.4f}\")\n",
        "print(f\"Final Validation Loss: {final_val_loss:.4f}\")\n",
        "print(f\"Final Validation Accuracy: {final_val_acc:.4f}\")\n",
        "\n",
        "# Display training results graph\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plot Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss', color='blue')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss Over Epochs\")\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy', color='blue')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy Over Epochs\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ifVtbvU52o4E"
      },
      "outputs": [],
      "source": [
        "# Modified AlexNet with CIFAR-100 with Dropout\n",
        "import datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "# Load CIFAR-100 dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
        "num_classes = 100\n",
        "\n",
        "# Normalize data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert labels to categorical\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Define AlexNet-based model with Dropout\n",
        "class SimpleAlexNetWithDropout(Sequential):\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.add(Conv2D(96, kernel_size=(3,3), strides=1, padding='same', activation='relu', input_shape=input_shape))\n",
        "        self.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "\n",
        "        self.add(Conv2D(192, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "        self.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "\n",
        "        self.add(Conv2D(384, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "        self.add(Conv2D(384, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "        self.add(Conv2D(256, kernel_size=(3,3), strides=1, padding='same', activation='relu'))\n",
        "        self.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "\n",
        "        self.add(Flatten())\n",
        "        self.add(Dense(1024, activation='relu'))\n",
        "        self.add(Dropout(0.5))  # Dropout added\n",
        "        self.add(Dense(1024, activation='relu'))\n",
        "        self.add(Dropout(0.5))  # Dropout added\n",
        "        self.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "        self.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Initialize model\n",
        "model = SimpleAlexNetWithDropout((32, 32, 3), num_classes)\n",
        "\n",
        "# Training parameters\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True)\n",
        "train_generator = train_datagen.flow(x_train, y_train, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Logging for TensorBoard\n",
        "tensorboard_callback = TensorBoard(log_dir=\"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[tensorboard_callback],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Display final training results\n",
        "final_train_loss = history.history['loss'][-1]\n",
        "final_train_acc = history.history['accuracy'][-1]\n",
        "final_val_loss = history.history['val_loss'][-1]\n",
        "final_val_acc = history.history['val_accuracy'][-1]\n",
        "\n",
        "print(f\"\\nFinal Training Loss: {final_train_loss:.4f}\")\n",
        "print(f\"Final Training Accuracy: {final_train_acc:.4f}\")\n",
        "print(f\"Final Validation Loss: {final_val_loss:.4f}\")\n",
        "print(f\"Final Validation Accuracy: {final_val_acc:.4f}\")\n",
        "\n",
        "# Display training results graph\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plot Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss', color='blue')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss Over Epochs\")\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy', color='blue')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy Over Epochs\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#vgg net cifar10 without dropout\n",
        "import datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "num_classes = 10\n",
        "\n",
        "# Normalize data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert labels to categorical\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Define a simplified VGG model\n",
        "class SimpleVGG(Sequential):\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        # First Conv Block\n",
        "        self.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu', input_shape=input_shape))\n",
        "        self.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "        self.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "\n",
        "        # Second Conv Block\n",
        "        self.add(Conv2D(128, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "        self.add(Conv2D(128, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "        self.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "\n",
        "        # Third Conv Block\n",
        "        self.add(Conv2D(256, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "        self.add(Conv2D(256, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "        self.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "\n",
        "        # Fully Connected Layers\n",
        "        self.add(Flatten())\n",
        "        self.add(Dense(512, activation='relu'))\n",
        "        self.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "        self.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Initialize model\n",
        "model = SimpleVGG((32, 32, 3), num_classes)\n",
        "\n",
        "# Training parameters\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True)\n",
        "train_generator = train_datagen.flow(x_train, y_train, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Logging for TensorBoard\n",
        "tensorboard_callback = TensorBoard(log_dir=\"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[tensorboard_callback],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Display final training results\n",
        "final_train_loss = history.history['loss'][-1]\n",
        "final_train_acc = history.history['accuracy'][-1]\n",
        "final_val_loss = history.history['val_loss'][-1]\n",
        "final_val_acc = history.history['val_accuracy'][-1]\n",
        "\n",
        "print(f\"\\nFinal Training Loss: {final_train_loss:.4f}\")\n",
        "print(f\"Final Training Accuracy: {final_train_acc:.4f}\")\n",
        "print(f\"Final Validation Loss: {final_val_loss:.4f}\")\n",
        "print(f\"Final Validation Accuracy: {final_val_acc:.4f}\")\n",
        "\n",
        "# Display training results graph\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plot Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss', color='blue')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss Over Epochs\")\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy', color='blue')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy Over Epochs\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "-yG7ByKPbMK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Modified VGG CIFAR 10 With Dropout\n",
        "import datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "num_classes = 10\n",
        "\n",
        "# Normalize data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert labels to categorical\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Define a VGG-like model with Dropout\n",
        "class SimpleVGG_Dropout(Sequential):\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        # First Conv Block\n",
        "        self.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu', input_shape=input_shape))\n",
        "        self.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "        self.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "\n",
        "        # Second Conv Block\n",
        "        self.add(Conv2D(128, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "        self.add(Conv2D(128, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "        self.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "\n",
        "        # Third Conv Block\n",
        "        self.add(Conv2D(256, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "        self.add(Conv2D(256, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "        self.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "\n",
        "        # Fully Connected Layers with Dropout\n",
        "        self.add(Flatten())\n",
        "        self.add(Dense(512, activation='relu'))\n",
        "        self.add(Dropout(0.5))  # 50% dropout\n",
        "        self.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "        self.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Initialize model\n",
        "model = SimpleVGG_Dropout((32, 32, 3), num_classes)\n",
        "\n",
        "# Training parameters\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True)\n",
        "train_generator = train_datagen.flow(x_train, y_train, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Logging for TensorBoard\n",
        "tensorboard_callback = TensorBoard(log_dir=\"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[tensorboard_callback],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Display final training results\n",
        "final_train_loss = history.history['loss'][-1]\n",
        "final_train_acc = history.history['accuracy'][-1]\n",
        "final_val_loss = history.history['val_loss'][-1]\n",
        "final_val_acc = history.history['val_accuracy'][-1]\n",
        "\n",
        "print(f\"\\nFinal Training Loss: {final_train_loss:.4f}\")\n",
        "print(f\"Final Training Accuracy: {final_train_acc:.4f}\")\n",
        "print(f\"Final Validation Loss: {final_val_loss:.4f}\")\n",
        "print(f\"Final Validation Accuracy: {final_val_acc:.4f}\")\n",
        "\n",
        "# Display training results graph\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plot Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss', color='blue')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss Over Epochs\")\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy', color='blue')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy Over Epochs\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "_Otv3sQobddN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#modified vgg with cifar100 with dropout\n",
        "import datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "# Load CIFAR-100 dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
        "num_classes = 100  # CIFAR-100 has 100 classes\n",
        "\n",
        "# Normalize data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert labels to categorical\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Define a VGG-like model for CIFAR-100 (with dropout)\n",
        "class SimpleVGG_CIFAR100_Dropout(Sequential):\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        # First Conv Block\n",
        "        self.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu', input_shape=input_shape))\n",
        "        self.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "        self.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "\n",
        "        # Second Conv Block\n",
        "        self.add(Conv2D(128, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "        self.add(Conv2D(128, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "        self.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "\n",
        "        # Third Conv Block\n",
        "        self.add(Conv2D(256, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "        self.add(Conv2D(256, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "        self.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
        "\n",
        "        # Fully Connected Layers with Dropout\n",
        "        self.add(Flatten())\n",
        "        self.add(Dense(512, activation='relu'))\n",
        "        self.add(Dropout(0.5))  # Dropout added\n",
        "        self.add(Dense(num_classes, activation='softmax'))  # 100 classes\n",
        "\n",
        "        self.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Initialize model\n",
        "model = SimpleVGG_CIFAR100_Dropout((32, 32, 3), num_classes)\n",
        "\n",
        "# Training parameters\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True)\n",
        "train_generator = train_datagen.flow(x_train, y_train, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Logging for TensorBoard\n",
        "tensorboard_callback = TensorBoard(log_dir=\"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[tensorboard_callback],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Display final training results\n",
        "final_train_loss = history.history['loss'][-1]\n",
        "final_train_acc = history.history['accuracy'][-1]\n",
        "final_val_loss = history.history['val_loss'][-1]\n",
        "final_val_acc = history.history['val_accuracy'][-1]\n",
        "\n",
        "print(f\"\\nFinal Training Loss: {final_train_loss:.4f}\")\n",
        "print(f\"Final Training Accuracy: {final_train_acc:.4f}\")\n",
        "print(f\"Final Validation Loss: {final_val_loss:.4f}\")\n",
        "print(f\"Final Validation Accuracy: {final_val_acc:.4f}\")\n",
        "\n",
        "# Display training results graph\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plot Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss', color='blue')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss Over Epochs\")\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy', color='blue')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy Over Epochs\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "at3KgbRgbnmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#resnet18 cifar10 without dropout\n",
        "import datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, ReLU, MaxPooling2D, Add, Flatten, Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "num_classes = 10\n",
        "\n",
        "# Normalize data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert labels to categorical\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "# Define Residual Block\n",
        "class ResidualBlock(Model):\n",
        "    def __init__(self, filters, downsample=False):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = Conv2D(filters, kernel_size=3, strides=1 if not downsample else 2, padding='same')\n",
        "        self.bn1 = BatchNormalization()\n",
        "        self.relu = ReLU()\n",
        "\n",
        "        self.conv2 = Conv2D(filters, kernel_size=3, strides=1, padding='same')\n",
        "        self.bn2 = BatchNormalization()\n",
        "\n",
        "        self.downsample = downsample\n",
        "        if downsample:\n",
        "            self.identity_downsample = Conv2D(filters, kernel_size=1, strides=2, padding='same')\n",
        "\n",
        "    def call(self, x):\n",
        "        identity = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "\n",
        "        if self.downsample:\n",
        "            identity = self.identity_downsample(identity)\n",
        "\n",
        "        x = Add()([x, identity])\n",
        "        x = ReLU()(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Define ResNet-18 Model\n",
        "class ResNet18(Model):\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        super(ResNet18, self).__init__()\n",
        "\n",
        "        self.conv1 = Conv2D(64, kernel_size=3, strides=1, padding='same', input_shape=input_shape)  # Changed kernel size from 7 to 3 (for CIFAR-10)\n",
        "        self.bn1 = BatchNormalization()\n",
        "        self.relu = ReLU()\n",
        "        self.maxpool = MaxPooling2D(pool_size=2, strides=2, padding='same')  # Reduced pooling size\n",
        "\n",
        "        # Residual layers\n",
        "        self.layer1 = self.make_layer(64, 2, downsample=False)\n",
        "        self.layer2 = self.make_layer(128, 2, downsample=True)\n",
        "        self.layer3 = self.make_layer(256, 2, downsample=True)\n",
        "        self.layer4 = self.make_layer(512, 2, downsample=True)\n",
        "\n",
        "        self.global_avg_pool = GlobalAveragePooling2D()  # **Fix: Using Global Average Pooling**\n",
        "        self.fc = Dense(num_classes, activation='softmax')\n",
        "\n",
        "    def make_layer(self, filters, blocks, downsample):\n",
        "        layers = []\n",
        "        layers.append(ResidualBlock(filters, downsample))\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(ResidualBlock(filters))\n",
        "        return layers\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        for layer in self.layer1:\n",
        "            x = layer(x)\n",
        "        for layer in self.layer2:\n",
        "            x = layer(x)\n",
        "        for layer in self.layer3:\n",
        "            x = layer(x)\n",
        "        for layer in self.layer4:\n",
        "            x = layer(x)\n",
        "\n",
        "        x = self.global_avg_pool(x)  # **Fix: Use GlobalAveragePooling2D**\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Initialize model\n",
        "input_shape = (32, 32, 3)\n",
        "model = ResNet18(input_shape, num_classes)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training parameters\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True)\n",
        "train_generator = train_datagen.flow(x_train, y_train, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Logging for TensorBoard\n",
        "tensorboard_callback = TensorBoard(log_dir=\"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[tensorboard_callback],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Display final training results\n",
        "final_train_loss = history.history['loss'][-1]\n",
        "final_train_acc = history.history['accuracy'][-1]\n",
        "final_val_loss = history.history['val_loss'][-1]\n",
        "final_val_acc = history.history['val_accuracy'][-1]\n",
        "\n",
        "print(f\"\\nFinal Training Loss: {final_train_loss:.4f}\")\n",
        "print(f\"Final Training Accuracy: {final_train_acc:.4f}\")\n",
        "print(f\"Final Validation Loss: {final_val_loss:.4f}\")\n",
        "print(f\"Final Validation Accuracy: {final_val_acc:.4f}\")\n",
        "\n",
        "# Display training results graph\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plot Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss', color='blue')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss Over Epochs\")\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy', color='blue')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy Over Epochs\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "qP3qbZV0bra1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#resnet-18 cifar10 with dropout\n",
        "import datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, ReLU, MaxPooling2D, Add, Flatten, Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "num_classes = 10\n",
        "\n",
        "# Normalize data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert labels to categorical\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "# Define Residual Block\n",
        "class ResidualBlock(Model):\n",
        "    def __init__(self, filters, downsample=False):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = Conv2D(filters, kernel_size=3, strides=1 if not downsample else 2, padding='same')\n",
        "        self.bn1 = BatchNormalization()\n",
        "        self.relu = ReLU()\n",
        "\n",
        "        self.conv2 = Conv2D(filters, kernel_size=3, strides=1, padding='same')\n",
        "        self.bn2 = BatchNormalization()\n",
        "\n",
        "        self.downsample = downsample\n",
        "        if downsample:\n",
        "            self.identity_downsample = Conv2D(filters, kernel_size=1, strides=2, padding='same')\n",
        "\n",
        "    def call(self, x):\n",
        "        identity = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "\n",
        "        if self.downsample:\n",
        "            identity = self.identity_downsample(identity)\n",
        "\n",
        "        x = Add()([x, identity])\n",
        "        x = ReLU()(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Define ResNet-18 Model with Dropout\n",
        "class ResNet18_Dropout(Model):\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        super(ResNet18_Dropout, self).__init__()\n",
        "\n",
        "        self.conv1 = Conv2D(64, kernel_size=3, strides=1, padding='same', input_shape=input_shape)  # Adjusted kernel for CIFAR-10\n",
        "        self.bn1 = BatchNormalization()\n",
        "        self.relu = ReLU()\n",
        "        self.maxpool = MaxPooling2D(pool_size=2, strides=2, padding='same')\n",
        "\n",
        "        # Residual layers\n",
        "        self.layer1 = self.make_layer(64, 2, downsample=False)\n",
        "        self.layer2 = self.make_layer(128, 2, downsample=True)\n",
        "        self.layer3 = self.make_layer(256, 2, downsample=True)\n",
        "        self.layer4 = self.make_layer(512, 2, downsample=True)\n",
        "\n",
        "        self.global_avg_pool = GlobalAveragePooling2D()\n",
        "        self.dropout = Dropout(0.5)  # **Added Dropout**\n",
        "        self.fc = Dense(num_classes, activation='softmax')\n",
        "\n",
        "    def make_layer(self, filters, blocks, downsample):\n",
        "        layers = []\n",
        "        layers.append(ResidualBlock(filters, downsample))\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(ResidualBlock(filters))\n",
        "        return layers\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        for layer in self.layer1:\n",
        "            x = layer(x)\n",
        "        for layer in self.layer2:\n",
        "            x = layer(x)\n",
        "        for layer in self.layer3:\n",
        "            x = layer(x)\n",
        "        for layer in self.layer4:\n",
        "            x = layer(x)\n",
        "\n",
        "        x = self.global_avg_pool(x)\n",
        "        x = self.dropout(x)  # **Dropout before the fully connected layer**\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Initialize model\n",
        "input_shape = (32, 32, 3)\n",
        "model = ResNet18_Dropout(input_shape, num_classes)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training parameters\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True)\n",
        "train_generator = train_datagen.flow(x_train, y_train, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Logging for TensorBoard\n",
        "tensorboard_callback = TensorBoard(log_dir=\"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[tensorboard_callback],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Display final training results\n",
        "final_train_loss = history.history['loss'][-1]\n",
        "final_train_acc = history.history['accuracy'][-1]\n",
        "final_val_loss = history.history['val_loss'][-1]\n",
        "final_val_acc = history.history['val_accuracy'][-1]\n",
        "\n",
        "print(f\"\\nFinal Training Loss: {final_train_loss:.4f}\")\n",
        "print(f\"Final Training Accuracy: {final_train_acc:.4f}\")\n",
        "print(f\"Final Validation Loss: {final_val_loss:.4f}\")\n",
        "print(f\"Final Validation Accuracy: {final_val_acc:.4f}\")\n",
        "\n",
        "# Display training results graph\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plot Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss', color='blue')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss Over Epochs\")\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy', color='blue')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy Over Epochs\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "KKVzjsSocK-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#resnet-18 cifar100 without dropout\n",
        "import datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, ReLU, MaxPooling2D, Add, Flatten, Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "# Load CIFAR-100 dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
        "num_classes = 100  # Adjusted for CIFAR-100\n",
        "\n",
        "# Normalize data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert labels to categorical\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "# Define Residual Block\n",
        "class ResidualBlock(Model):\n",
        "    def __init__(self, filters, downsample=False):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = Conv2D(filters, kernel_size=3, strides=1 if not downsample else 2, padding='same')\n",
        "        self.bn1 = BatchNormalization()\n",
        "        self.relu = ReLU()\n",
        "\n",
        "        self.conv2 = Conv2D(filters, kernel_size=3, strides=1, padding='same')\n",
        "        self.bn2 = BatchNormalization()\n",
        "\n",
        "        self.downsample = downsample\n",
        "        if downsample:\n",
        "            self.identity_downsample = Conv2D(filters, kernel_size=1, strides=2, padding='same')\n",
        "\n",
        "    def call(self, x):\n",
        "        identity = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "\n",
        "        if self.downsample:\n",
        "            identity = self.identity_downsample(identity)\n",
        "\n",
        "        x = Add()([x, identity])\n",
        "        x = ReLU()(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Define ResNet-18 Model (CIFAR-100, No Dropout)\n",
        "class ResNet18_CIFAR100(Model):\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        super(ResNet18_CIFAR100, self).__init__()\n",
        "\n",
        "        self.conv1 = Conv2D(64, kernel_size=3, strides=1, padding='same', input_shape=input_shape)  # Adjusted kernel for CIFAR-100\n",
        "        self.bn1 = BatchNormalization()\n",
        "        self.relu = ReLU()\n",
        "        self.maxpool = MaxPooling2D(pool_size=2, strides=2, padding='same')\n",
        "\n",
        "        # Residual layers\n",
        "        self.layer1 = self.make_layer(64, 2, downsample=False)\n",
        "        self.layer2 = self.make_layer(128, 2, downsample=True)\n",
        "        self.layer3 = self.make_layer(256, 2, downsample=True)\n",
        "        self.layer4 = self.make_layer(512, 2, downsample=True)\n",
        "\n",
        "        self.global_avg_pool = GlobalAveragePooling2D()\n",
        "        self.fc = Dense(num_classes, activation='softmax')  # Adjusted for 100 classes\n",
        "\n",
        "    def make_layer(self, filters, blocks, downsample):\n",
        "        layers = []\n",
        "        layers.append(ResidualBlock(filters, downsample))\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(ResidualBlock(filters))\n",
        "        return layers\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        for layer in self.layer1:\n",
        "            x = layer(x)\n",
        "        for layer in self.layer2:\n",
        "            x = layer(x)\n",
        "        for layer in self.layer3:\n",
        "            x = layer(x)\n",
        "        for layer in self.layer4:\n",
        "            x = layer(x)\n",
        "\n",
        "        x = self.global_avg_pool(x)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Initialize model\n",
        "input_shape = (32, 32, 3)\n",
        "model = ResNet18_CIFAR100(input_shape, num_classes)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training parameters\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True)\n",
        "train_generator = train_datagen.flow(x_train, y_train, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Logging for TensorBoard\n",
        "tensorboard_callback = TensorBoard(log_dir=\"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[tensorboard_callback],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Display final training results\n",
        "final_train_loss = history.history['loss'][-1]\n",
        "final_train_acc = history.history['accuracy'][-1]\n",
        "final_val_loss = history.history['val_loss'][-1]\n",
        "final_val_acc = history.history['val_accuracy'][-1]\n",
        "\n",
        "print(f\"\\nFinal Training Loss: {final_train_loss:.4f}\")\n",
        "print(f\"Final Training Accuracy: {final_train_acc:.4f}\")\n",
        "print(f\"Final Validation Loss: {final_val_loss:.4f}\")\n",
        "print(f\"Final Validation Accuracy: {final_val_acc:.4f}\")\n",
        "\n",
        "# Display training results graph\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plot Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss', color='blue')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss Over Epochs\")\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy', color='blue')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy Over Epochs\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "o2UyqOPWcwp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#resnet-18 with cifar100 with dropout\n",
        "import datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, ReLU, MaxPooling2D, Add, Flatten, Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "# Load CIFAR-100 dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
        "num_classes = 100  # Adjusted for CIFAR-100\n",
        "\n",
        "# Normalize data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Convert labels to categorical\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "# Define Residual Block\n",
        "class ResidualBlock(Model):\n",
        "    def __init__(self, filters, downsample=False):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = Conv2D(filters, kernel_size=3, strides=1 if not downsample else 2, padding='same')\n",
        "        self.bn1 = BatchNormalization()\n",
        "        self.relu = ReLU()\n",
        "\n",
        "        self.conv2 = Conv2D(filters, kernel_size=3, strides=1, padding='same')\n",
        "        self.bn2 = BatchNormalization()\n",
        "\n",
        "        self.downsample = downsample\n",
        "        if downsample:\n",
        "            self.identity_downsample = Conv2D(filters, kernel_size=1, strides=2, padding='same')\n",
        "\n",
        "    def call(self, x):\n",
        "        identity = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "\n",
        "        if self.downsample:\n",
        "            identity = self.identity_downsample(identity)\n",
        "\n",
        "        x = Add()([x, identity])\n",
        "        x = ReLU()(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Define ResNet-18 Model (CIFAR-100, With Dropout)\n",
        "class ResNet18_CIFAR100_Dropout(Model):\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        super(ResNet18_CIFAR100_Dropout, self).__init__()\n",
        "\n",
        "        self.conv1 = Conv2D(64, kernel_size=3, strides=1, padding='same', input_shape=input_shape)  # Adjusted kernel for CIFAR-100\n",
        "        self.bn1 = BatchNormalization()\n",
        "        self.relu = ReLU()\n",
        "        self.maxpool = MaxPooling2D(pool_size=2, strides=2, padding='same')\n",
        "\n",
        "        # Residual layers\n",
        "        self.layer1 = self.make_layer(64, 2, downsample=False)\n",
        "        self.layer2 = self.make_layer(128, 2, downsample=True)\n",
        "        self.layer3 = self.make_layer(256, 2, downsample=True)\n",
        "        self.layer4 = self.make_layer(512, 2, downsample=True)\n",
        "\n",
        "        self.global_avg_pool = GlobalAveragePooling2D()\n",
        "        self.dropout = Dropout(0.5)  # **Added Dropout**\n",
        "        self.fc = Dense(num_classes, activation='softmax')  # Adjusted for 100 classes\n",
        "\n",
        "    def make_layer(self, filters, blocks, downsample):\n",
        "        layers = []\n",
        "        layers.append(ResidualBlock(filters, downsample))\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(ResidualBlock(filters))\n",
        "        return layers\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        for layer in self.layer1:\n",
        "            x = layer(x)\n",
        "        for layer in self.layer2:\n",
        "            x = layer(x)\n",
        "        for layer in self.layer3:\n",
        "            x = layer(x)\n",
        "        for layer in self.layer4:\n",
        "            x = layer(x)\n",
        "\n",
        "        x = self.global_avg_pool(x)\n",
        "        x = self.dropout(x)  # **Dropout before the fully connected layer**\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Initialize model\n",
        "input_shape = (32, 32, 3)\n",
        "model = ResNet18_CIFAR100_Dropout(input_shape, num_classes)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training parameters\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True)\n",
        "train_generator = train_datagen.flow(x_train, y_train, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Logging for TensorBoard\n",
        "tensorboard_callback = TensorBoard(log_dir=\"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[tensorboard_callback],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Display final training results\n",
        "final_train_loss = history.history['loss'][-1]\n",
        "final_train_acc = history.history['accuracy'][-1]\n",
        "final_val_loss = history.history['val_loss'][-1]\n",
        "final_val_acc = history.history['val_accuracy'][-1]\n",
        "\n",
        "print(f\"\\nFinal Training Loss: {final_train_loss:.4f}\")\n",
        "print(f\"Final Training Accuracy: {final_train_acc:.4f}\")\n",
        "print(f\"Final Validation Loss: {final_val_loss:.4f}\")\n",
        "print(f\"Final Validation Accuracy: {final_val_acc:.4f}\")\n",
        "\n",
        "# Display training results graph\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plot Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss', color='blue')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss Over Epochs\")\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy', color='blue')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy Over Epochs\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "oe4AyGa9dxZS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMs6GHS+xRZxoK1rfxnxEr4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}